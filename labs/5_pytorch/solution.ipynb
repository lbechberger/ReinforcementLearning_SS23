{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOBUyiZq3d2u"
   },
   "source": [
    "# Minimal PyTorch Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvwPL6u83aNe"
   },
   "source": [
    "This notebooks shows a very minimal example on how to use PyTorch for training a neural network on the Iris data set.\n",
    "\n",
    "Note: This notebook is inspired by https://jamesmccaffrey.wordpress.com/2020/05/22/a-minimal-pytorch-complete-example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhdvnPe4Q-pO"
   },
   "source": [
    "### 0. Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K8-YOrlu3w8z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tf59x5HX3zMO"
   },
   "source": [
    "The following lines checks for GPU availability on the machine and sets the GPU as processing device (if available).\n",
    "If you are on Colab you can enable GPU support in the menu via  \"Runtime > Change runtime type\" and select \"GPU\" as hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3DgoJj735Gr",
    "outputId": "237e74c2-d010-43d4-d5c2-12e699e8737b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "  processing_chip = \"cuda:0\"\n",
    "  print(f\"{torch.cuda.get_device_name(0)} available\")\n",
    "else:\n",
    "  processing_chip = \"cpu\"\n",
    "  print(\"No GPU available\")\n",
    "\n",
    "device = torch.device(processing_chip)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8EgmXccAr9b"
   },
   "source": [
    "### 1. Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQbkjF8hstMZ"
   },
   "source": [
    "For this small example we use the [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set). The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on these four features, we want to train a model that can predict the species.\n",
    "\n",
    "In the first step we load the data into a Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "DZoYUZfQ_TU8",
    "outputId": "99015012-d895-4d45-fdd0-477edcf22019"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'data/iris.csv'\n",
    "dataset = pd.read_csv(url)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wk_OnO451DX"
   },
   "source": [
    "To be able to train a model, we first need to transform the *species* column into a numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "fQqdZZ16AHBe",
    "outputId": "155138d4-b609-47b1-d9fa-12e59ebbf101"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2       0\n",
       "1           4.9          3.0           1.4          0.2       0\n",
       "2           4.7          3.2           1.3          0.2       0\n",
       "3           4.6          3.1           1.5          0.2       0\n",
       "4           5.0          3.6           1.4          0.2       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[dataset.species=='Iris-setosa', 'species'] = 0\n",
    "dataset.loc[dataset.species=='Iris-versicolor', 'species'] = 1\n",
    "dataset.loc[dataset.species=='Iris-virginica', 'species'] = 2\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYLgEfDUPu2_"
   },
   "source": [
    "Next, we specify which columns we want to use as features and which as label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-uHB8hU0A4sI"
   },
   "outputs": [],
   "source": [
    "X = dataset[dataset.columns[0:4]].values\n",
    "y = dataset.species.values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNUlUKPYtz8C"
   },
   "source": [
    "We then split our data into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQvkW7kct2Ry",
    "outputId": "a40538f1-f053-41e4-a11a-f2564b4cd230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56Ep6AWT5-Wy"
   },
   "source": [
    "To be able to use the data in PyTorch, we need to convert them into PyTorch tensors. Such a tensor can be thought of an efficient way to represent lists and matrices (similar to Numpy), with the additional benefit that they can be moved to the GPU (the `.to(device)` part in the code below) and that they support automatic backpropagation (more on this later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-OI44o3i-grB"
   },
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_X).float().to(device)\n",
    "test_x = torch.Tensor(test_X).float().to(device)\n",
    "train_y =torch.Tensor(train_y).long().to(device)\n",
    "test_y = torch.Tensor(test_y).long().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wcTXnyu7NWK"
   },
   "source": [
    "### 2. Model definition\n",
    "We define now the strucutre of our neural network. For this we create a class that is a subclass from PyTorch's `nn.Module`.\n",
    "By convention we put in the `__init__` method the layers we want to use in the network and in the `forward` method how data flows through this network.\n",
    "\n",
    "Our network has 4 input features, 7 hidden layer nodes and 3 output neurons. The hidden layer uses a Relu activation function. Note that the output layer does not have a softmax activation (unlike we have seen it in the lecture). It rather gives out a raw score for each class (more on this later). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_W47oZ534E-1"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = nn.Linear(4, 7) \n",
    "        self.hidden2 = nn.Linear(7, 5) # change for Task 2\n",
    "        self.output = nn.Linear(5, 3) # change for Task 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        z1 = self.hidden1(x)\n",
    "        z2 = F.relu(z1)\n",
    "        z3 = self.hidden2(z2) # change for Task 2\n",
    "        z4 = F.relu(z3)       # change for Task 2\n",
    "        z5 = self.output(z4)  # change for Task 2; no softmax. see CrossEntropyLoss() \n",
    "        return z5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJyy5JG_84vs"
   },
   "source": [
    "### 3. Model Training\n",
    "We can now start training our network. We run several epochs in which we first predict on the training data with our network and than backpropagate the loss. For this we use PyTorch's build-in optimizer that runs gradient descent on the weights of the network. Hence, in every episode we reduce the loss on the training data and improve our network.\n",
    "\n",
    "As loss function we use cross entropy, which consumes the raw scores from the prediction and internally applies a softmax (that is why we do not need the softmax as last layer in the network).\n",
    "\n",
    "Note that all training data is passed at once to our network (line `net(train_x)`), since PyTorch will predict on all data points in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden1): Linear(in_features=4, out_features=7, bias=True)\n",
       "  (hidden2): Linear(in_features=7, out_features=5, bias=True)\n",
       "  (output): Linear(in_features=5, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create network, move it to device (either CPU or GPU), and set it to training mode\n",
    "net = Net().to(device)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RQHZvvyAFzV",
    "outputId": "2b547d37-3b71-4b1f-8e6a-50e69d0d2a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training \n",
      "Loss in epoch 0 is 0.9038964509963989\n",
      "Loss in epoch 10 is 0.8249509930610657\n",
      "Loss in epoch 20 is 0.7307508587837219\n",
      "Loss in epoch 30 is 0.6387642025947571\n",
      "Loss in epoch 40 is 0.5645408034324646\n",
      "Loss in epoch 50 is 0.5088369846343994\n",
      "Loss in epoch 60 is 0.4654156267642975\n",
      "Loss in epoch 70 is 0.4292605221271515\n",
      "Loss in epoch 80 is 0.39734676480293274\n",
      "Loss in epoch 90 is 0.3678705394268036\n",
      "Loss in epoch 100 is 0.3398509621620178\n",
      "Loss in epoch 110 is 0.31288284063339233\n",
      "Loss in epoch 120 is 0.28715163469314575\n",
      "Loss in epoch 130 is 0.2630310654640198\n",
      "Loss in epoch 140 is 0.24091897904872894\n",
      "Loss in epoch 150 is 0.22426123917102814\n",
      "Loss in epoch 160 is 0.24908393621444702\n",
      "Loss in epoch 170 is 0.3230430781841278\n",
      "Loss in epoch 180 is 0.29318034648895264\n",
      "Loss in epoch 190 is 0.2754005193710327\n",
      "Loss in epoch 200 is 0.2671451270580292\n",
      "Loss in epoch 210 is 0.26012489199638367\n",
      "Loss in epoch 220 is 0.25110501050949097\n",
      "Loss in epoch 230 is 0.23860317468643188\n",
      "Loss in epoch 240 is 0.22405001521110535\n",
      "Loss in epoch 250 is 0.20939482748508453\n",
      "Loss in epoch 260 is 0.19463281333446503\n",
      "Loss in epoch 270 is 0.17514117062091827\n",
      "Loss in epoch 280 is 0.15278325974941254\n",
      "Loss in epoch 290 is 0.16080932319164276\n",
      "Loss in epoch 300 is 0.16189990937709808\n",
      "Loss in epoch 310 is 0.14153634011745453\n",
      "Loss in epoch 320 is 0.14050087332725525\n",
      "Loss in epoch 330 is 0.13487108051776886\n",
      "Loss in epoch 340 is 0.14612413942813873\n",
      "Loss in epoch 350 is 0.131684347987175\n",
      "Loss in epoch 360 is 0.13714757561683655\n",
      "Loss in epoch 370 is 0.1353539526462555\n",
      "Loss in epoch 380 is 0.13105040788650513\n",
      "Loss in epoch 390 is 0.1239074245095253\n",
      "Done training \n"
     ]
    }
   ],
   "source": [
    "# define the parameters for training\n",
    "no_epochs = 400 # change for Task 2\n",
    "learning_rate = 0.04\n",
    "loss_func = nn.CrossEntropyLoss()  # applies softmax() internally\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"\\nStarting training \")\n",
    "\n",
    "train_losses = []\n",
    "for epoch in range(0, no_epochs):\n",
    "\n",
    "    optimizer.zero_grad()  # set gradients to zero \n",
    "    predictions = net(train_x)  # predict on the training data, this calls net.forward() \n",
    "\n",
    "    loss = loss_func(predictions, train_y)  # compute loss between prediction and true labels\n",
    "    loss.backward() # calculate the gradients for every weight\n",
    "    optimizer.step() # do one step of gradient descent\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Loss in epoch {epoch} is {loss.item()}\")\n",
    "\n",
    "print(\"Done training \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "fMPxG1i873W7",
    "outputId": "5d551446-3235-48e3-c45b-f0eececf763a"
   },
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(0, no_epochs), train_losses, color='blue')\n",
    "plt.legend(['Train Loss'], loc='upper right')\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cN8btFSP3yU2"
   },
   "source": [
    "### 4. Model Evaluation\n",
    "Finally, we check the model accuracy on the test data. For this we predict on the test data, identify the class with the highest score and compare it to the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsmVfo49Kytp",
    "outputId": "0659c70b-22cd-4ea2-b81f-221db140fdf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy is 90.0%\n"
     ]
    }
   ],
   "source": [
    "net.eval() # set the network to evaluation mode\n",
    "predictions = net(test_x)\n",
    "predicted = torch.argmax(predictions.data, 1) # get the class with highest score\n",
    "correct = (predicted == test_y).sum().item() # compare predicted class with real class\n",
    "print(f\"Accuarcy is {100. * correct / len(test_x)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Task 2\n",
    "Already directly done in the code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Solution Task 3\n",
    "First, transform the features into a torch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [4.9, 3.0, 1.4, 0.2]\n",
    "torch_x = torch.Tensor(x).float().to(device)\n",
    "torch_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, get the prediction (raw values, since we did not use a softmax inside the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  8.0056,   2.8565, -12.7938], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net(torch_x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally: Apply softmax to get class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.9423e-01, 5.7711e-03, 9.2139e-10], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=0)\n",
    "softmax(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMS3a9VIGYE8gp8KPG6Vfus",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "4_PyTorch_Example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
